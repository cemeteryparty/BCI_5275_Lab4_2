{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5275_Lab4_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dLUI5Hg-oXz"
      },
      "source": [
        "!ls -al /content/drive/MyDrive/lab4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGvhNc-R77KO"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "from torchsummary import summary\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from time import time as Timer\n",
        "from scipy.io import loadmat\n",
        "import numpy as np\n",
        "import math, sys\n",
        "\n",
        "DATASET_DIR = \"/content/drive/MyDrive/AE-4-EEG-Artifact-Removal/BCICIV2a/\"\n",
        "BASE_DIR = \"/content/drive/MyDrive/lab4/\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# torch shape: (batch_size, chan (depth), h, w)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucxAR2cT8yFz"
      },
      "source": [
        "class EEGNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EEGNet, self).__init__()\n",
        "\n",
        "        self.F1 = 8\n",
        "        self.F2 = 16\n",
        "        self.D = 2\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, self.F1, (1, 64), padding=(0, 32), bias=False),\n",
        "            nn.BatchNorm2d(self.F1)\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(self.F1, self.D*self.F1, (22, 1), groups=self.F1, bias=False),\n",
        "            nn.BatchNorm2d(self.D*self.F1),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d((1, 4)),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "        self.Conv3 = nn.Sequential(\n",
        "            nn.Conv2d(self.D*self.F1, self.D*self.F1, (1, 16), padding=(0, 8), groups=self.D*self.F1, bias=False),\n",
        "            nn.Conv2d(self.D*self.F1, self.F2, (1, 1), bias=False),\n",
        "            nn.BatchNorm2d(self.F2),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d((1, 8)),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(16*17, 4, bias=True)\n",
        "        #self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.Conv3(x)\n",
        "        \n",
        "        x = x.view(-1, 16*17)\n",
        "        x = self.classifier(x)\n",
        "        #x = self.softmax(x)\n",
        "        return x"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3tl_gY69J50"
      },
      "source": [
        "class ShallowConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ShallowConvNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 40, (1, 13), bias=False)\n",
        "        self.conv2 = nn.Conv2d(40, 40, (22, 1), bias=False)\n",
        "        self.Bn1   = nn.BatchNorm2d(40)\n",
        "        # self.SquareLayer = square_layer()\n",
        "        self.AvgPool1 = nn.AvgPool2d((1, 35), stride=(1, 7))\n",
        "        # self.LogLayer = Log_layer()\n",
        "        self.Drop1 = nn.Dropout(0.25)\n",
        "        self.classifier = nn.Linear(40*74, 4, bias=True)\n",
        "        #self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.Bn1(x)\n",
        "        x = x ** 2\n",
        "        x = self.AvgPool1(x)\n",
        "        x = torch.log(x)\n",
        "        x = self.Drop1(x)\n",
        "        x = x.view(-1, 40*74)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        #x = self.softmax(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVO_wSNW9MaK"
      },
      "source": [
        "class SCCNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SCCNet, self).__init__()\n",
        "        # bs, 1, channel, sample\n",
        "        self.conv1 = nn.Conv2d(1, 22, (22, 1))\n",
        "        self.Bn1 = nn.BatchNorm2d(22)\n",
        "        # bs, 22, 1, sample\n",
        "        self.conv2 = nn.Conv2d(22, 20, (1, 12), padding=(0, 6))\n",
        "        self.Bn2   = nn.BatchNorm2d(20)\n",
        "        # self.SquareLayer = square_layer()\n",
        "        self.Drop1 = nn.Dropout(0.5)\n",
        "        self.AvgPool1 = nn.AvgPool2d((1, 62), stride=(1, 12))\n",
        "        self.classifier = nn.Linear(840, 4, bias=True)\n",
        "        #self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.Bn1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.Bn2(x)\n",
        "        x = x ** 2\n",
        "        x = self.Drop1(x)\n",
        "        x = self.AvgPool1(x)\n",
        "        x = torch.log(x)\n",
        "        x = x.view(-1, 840)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        #x = self.softmax(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyFvsxUJ9PCU"
      },
      "source": [
        "class TSception(nn.Module):\n",
        "    def conv_block(self, in_chan, out_chan, kernel, step, pool):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_chan, out_channels=out_chan,\n",
        "                      kernel_size=kernel, stride=step, padding=0),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.AvgPool2d(kernel_size=(1, pool), stride=(1, pool)))\n",
        "\n",
        "    def __init__(self, num_classes, input_size, sampling_rate, num_T, num_S, hidden, dropout_rate):\n",
        "        # input_size: 1 x EEG channel x datapoint\n",
        "        super(TSception, self).__init__()\n",
        "        self.inception_window = [0.5, 0.25, 0.125]\n",
        "        self.pool = 8\n",
        "        # by setting the convolutional kernel being (1,lenght) and the strids being 1 we can use conv2d to\n",
        "        # achieve the 1d convolution operation\n",
        "        self.Tception1 = self.conv_block(1, num_T, (1, int(self.inception_window[0] * sampling_rate)), 1, self.pool)\n",
        "        self.Tception2 = self.conv_block(1, num_T, (1, int(self.inception_window[1] * sampling_rate)), 1, self.pool)\n",
        "        self.Tception3 = self.conv_block(1, num_T, (1, int(self.inception_window[2] * sampling_rate)), 1, self.pool)\n",
        "\n",
        "        self.Sception1 = self.conv_block(num_T, num_S, (int(input_size[1]), 1), 1, int(self.pool*0.25))\n",
        "        self.Sception2 = self.conv_block(num_T, num_S, (int(input_size[1] * 0.5), 1), (int(input_size[1] * 0.5), 1),\n",
        "                                         int(self.pool*0.25))\n",
        "        self.fusion_layer = self.conv_block(num_S, num_S, (3, 1), 1, 2)\n",
        "        self.BN_t = nn.BatchNorm2d(num_T)\n",
        "        self.BN_s = nn.BatchNorm2d(num_S)\n",
        "        self.BN_fusion = nn.BatchNorm2d(num_S)\n",
        "\n",
        "        size = self.get_size(input_size)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(size[1], hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden, num_classes),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.Tception1(x)\n",
        "        out = y\n",
        "        y = self.Tception2(x)\n",
        "        out = torch.cat((out, y), dim=-1)\n",
        "        y = self.Tception3(x)\n",
        "        out = torch.cat((out, y), dim=-1)\n",
        "        out = self.BN_t(out)\n",
        "        z = self.Sception1(out)\n",
        "        out_ = z\n",
        "        z = self.Sception2(out)\n",
        "        out_ = torch.cat((out_, z), dim=2)\n",
        "\n",
        "        out = self.BN_s(out_)\n",
        "        out = self.fusion_layer(out)\n",
        "        out = self.BN_fusion(out)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "    def get_size(self, input_size):\n",
        "        # here we use an array with the shape being\n",
        "        # (1(mini-batch),1(convolutional channel),EEG channel,time data point)\n",
        "        # to simulate the input data and get the output size\n",
        "        data = torch.ones((1, input_size[0], input_size[1], int(input_size[2])))\n",
        "        y = self.Tception1(data)\n",
        "        out = y\n",
        "        y = self.Tception2(data)\n",
        "        out = torch.cat((out, y), dim=-1)\n",
        "        y = self.Tception3(data)\n",
        "        out = torch.cat((out, y), dim=-1)\n",
        "        out = self.BN_t(out)\n",
        "        z = self.Sception1(out)\n",
        "        out_final = z\n",
        "        z = self.Sception2(out)\n",
        "        out_final = torch.cat((out_final, z), dim=2)\n",
        "        out = self.BN_s(out_final)\n",
        "        out = self.fusion_layer(out)\n",
        "        out = self.BN_fusion(out)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        return out.size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD01PDKmv2zz"
      },
      "source": [
        "class Model(object):\n",
        "    def __init__(self, model=None, lr=0.001):\n",
        "        super(Model, self).__init__()\n",
        "        self.model = model\n",
        "        self.losses = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    def fit(self, trainloader=None, validloader=None, epochs=1):\n",
        "        doValid = False if validloader == None else True\n",
        "        history = {\"loss\": [], \"acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
        "        for ep in range(epochs):\n",
        "            proc_start = Timer() # timer start\n",
        "            print(f\"Epoch {ep + 1}/{epochs}\")\n",
        "            self.model.train()\n",
        "            for x_batch, y_batch in trainloader:\n",
        "                print(\"█\", end=\"\")\n",
        "                x_batch, y_batch = x_batch.to(device, dtype=torch.float), y_batch.to(device)\n",
        "                pred = self.model(x_batch)\n",
        "                loss = self.losses(pred, y_batch)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                self.optimizer.zero_grad()\n",
        "            proc_end = Timer() # timer stop\n",
        "\n",
        "            loss, acc = self.evaluate(trainloader, dumpstr=False)\n",
        "            val_loss, val_acc = self.evaluate(validloader, dumpstr=False) if doValid else (0, 0)\n",
        "            history[\"loss\"] = np.append(history[\"loss\"], loss)\n",
        "            history[\"acc\"] = np.append(history[\"acc\"], acc)\n",
        "            history[\"val_loss\"] = np.append(history[\"val_loss\"], val_loss)\n",
        "            history[\"val_acc\"] = np.append(history[\"val_acc\"], val_acc)\n",
        "            print(\" {:.4f}s - loss: {:.4f} - acc: {:.4f} - val_loss: {:.4f} - val_acc: {:.4f}\".format(\n",
        "                proc_end-proc_start, history[\"loss\"][-1], history[\"acc\"][-1], history[\"val_loss\"][-1], history[\"val_acc\"][-1])\n",
        "            )\n",
        "        return history\n",
        "    def evaluate(self, dataloader, dumpstr=True):\n",
        "        total, acc = 0, 0\n",
        "        self.model.eval()\n",
        "        for x_batch, y_batch in dataloader:\n",
        "            x_batch, y_batch = x_batch.to(device, dtype=torch.float), y_batch.to(device)\n",
        "            pred = self.model(x_batch)\n",
        "            loss = self.losses(pred, y_batch).item()\n",
        "            total += y_batch.shape[0]\n",
        "            acc += (torch.sum(pred.argmax(dim=1)==y_batch)).item()\n",
        "        acc /= total\n",
        "        if dumpstr:\n",
        "            print(f\"Accuracy: {acc:.4f}\\tLoss: {loss:.4f}\")\n",
        "        else:\n",
        "            return (loss, acc)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7rgfaiJ-LQU"
      },
      "source": [
        "train_raw = loadmat(DATASET_DIR + \"BCIC_S01_T.mat\")\n",
        "test_raw = loadmat(DATASET_DIR + \"BCIC_S01_E.mat\")\n",
        "trX, trY, teX, teY = train_raw[\"x_train\"], train_raw[\"y_train\"], test_raw[\"x_test\"], test_raw[\"y_test\"]"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tqCpBDxUY1i",
        "outputId": "f0f51588-c2a2-41df-fdcc-b7796af0349e"
      },
      "source": [
        "x_train = torch.from_numpy(np.expand_dims(trX, axis=1))\n",
        "y_train = torch.from_numpy(np.reshape(trY, (trY.size, ))).long()\n",
        "x_test = torch.from_numpy(np.expand_dims(teX, axis=1))\n",
        "y_test = torch.from_numpy(np.reshape(teY, (teY.size, ))).long()\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "trainset, testset = TensorDataset(x_train, y_train), TensorDataset(x_test, y_test)\n",
        "\n",
        "\"\"\" create dataloader \"\"\"\n",
        "bs = 32 # batch_size\n",
        "trainloader = DataLoader(dataset=trainset, batch_size=bs, shuffle=True)\n",
        "testloader = DataLoader(dataset=testset, batch_size=bs, shuffle=True)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([288, 1, 22, 562]) torch.Size([288])\n",
            "torch.Size([288, 1, 22, 562]) torch.Size([288])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivZTvIlyG_0a",
        "outputId": "fd8e4439-136d-4db5-8d80-04afd3890880"
      },
      "source": [
        "eegnet = EEGNet().to(device)\n",
        "\n",
        "model = Model(eegnet, lr=0.001)\n",
        "history = model.fit(trainloader=trainloader, validloader=testloader, epochs=500)\n",
        "model.evaluate(dataloader=trainloader)\n",
        "model.evaluate(dataloader=testloader)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "█████████ 0.0822s - loss: 1.3803 - acc: 0.2812 - val_loss: 1.3871 - val_acc: 0.2812\n",
            "Epoch 2/500\n",
            "█████████ 0.0780s - loss: 1.3738 - acc: 0.3090 - val_loss: 1.3846 - val_acc: 0.3021\n",
            "Epoch 3/500\n",
            "█████████ 0.0814s - loss: 1.3696 - acc: 0.3507 - val_loss: 1.3699 - val_acc: 0.3368\n",
            "Epoch 4/500\n",
            "█████████ 0.0780s - loss: 1.3418 - acc: 0.4688 - val_loss: 1.3663 - val_acc: 0.4028\n",
            "Epoch 5/500\n",
            "█████████ 0.0822s - loss: 1.3088 - acc: 0.5382 - val_loss: 1.3322 - val_acc: 0.4479\n",
            "Epoch 6/500\n",
            "█████████ 0.0843s - loss: 1.2602 - acc: 0.6076 - val_loss: 1.2658 - val_acc: 0.4826\n",
            "Epoch 7/500\n",
            "█████████ 0.0817s - loss: 1.1026 - acc: 0.5799 - val_loss: 1.1830 - val_acc: 0.5069\n",
            "Epoch 8/500\n",
            "█████████ 0.0790s - loss: 1.1119 - acc: 0.5868 - val_loss: 1.1090 - val_acc: 0.5208\n",
            "Epoch 9/500\n",
            "█████████ 0.0919s - loss: 0.9373 - acc: 0.5799 - val_loss: 1.0363 - val_acc: 0.5069\n",
            "Epoch 10/500\n",
            "█████████ 0.0783s - loss: 0.9193 - acc: 0.5938 - val_loss: 1.0204 - val_acc: 0.5208\n",
            "Epoch 11/500\n",
            "█████████ 0.0875s - loss: 0.7534 - acc: 0.5903 - val_loss: 0.8558 - val_acc: 0.5382\n",
            "Epoch 12/500\n",
            "█████████ 0.0768s - loss: 0.6909 - acc: 0.5938 - val_loss: 0.8659 - val_acc: 0.5417\n",
            "Epoch 13/500\n",
            "█████████ 0.0817s - loss: 0.6897 - acc: 0.6181 - val_loss: 0.9441 - val_acc: 0.5521\n",
            "Epoch 14/500\n",
            "█████████ 0.0803s - loss: 0.7651 - acc: 0.6424 - val_loss: 0.7327 - val_acc: 0.5382\n",
            "Epoch 15/500\n",
            "█████████ 0.0836s - loss: 0.6319 - acc: 0.6701 - val_loss: 0.7476 - val_acc: 0.5764\n",
            "Epoch 16/500\n",
            "█████████ 0.0771s - loss: 0.7448 - acc: 0.6806 - val_loss: 0.8455 - val_acc: 0.5903\n",
            "Epoch 17/500\n",
            "█████████ 0.0769s - loss: 0.7229 - acc: 0.6944 - val_loss: 0.6846 - val_acc: 0.6042\n",
            "Epoch 18/500\n",
            "█████████ 0.0759s - loss: 0.6801 - acc: 0.7083 - val_loss: 0.8610 - val_acc: 0.6076\n",
            "Epoch 19/500\n",
            "█████████ 0.0867s - loss: 0.7938 - acc: 0.7222 - val_loss: 0.9317 - val_acc: 0.6146\n",
            "Epoch 20/500\n",
            "█████████ 0.0767s - loss: 0.6567 - acc: 0.7361 - val_loss: 0.8035 - val_acc: 0.6319\n",
            "Epoch 21/500\n",
            "█████████ 0.0826s - loss: 0.6853 - acc: 0.7292 - val_loss: 0.6596 - val_acc: 0.6146\n",
            "Epoch 22/500\n",
            "█████████ 0.0821s - loss: 0.6028 - acc: 0.7535 - val_loss: 0.7251 - val_acc: 0.6354\n",
            "Epoch 23/500\n",
            "█████████ 0.0810s - loss: 0.4604 - acc: 0.7778 - val_loss: 0.7288 - val_acc: 0.6458\n",
            "Epoch 24/500\n",
            "█████████ 0.0853s - loss: 0.6070 - acc: 0.7917 - val_loss: 0.6387 - val_acc: 0.6562\n",
            "Epoch 25/500\n",
            "█████████ 0.0903s - loss: 0.4830 - acc: 0.7674 - val_loss: 0.5699 - val_acc: 0.6528\n",
            "Epoch 26/500\n",
            "█████████ 0.0803s - loss: 0.5981 - acc: 0.7743 - val_loss: 0.7524 - val_acc: 0.6632\n",
            "Epoch 27/500\n",
            "█████████ 0.0830s - loss: 0.5189 - acc: 0.7882 - val_loss: 0.7613 - val_acc: 0.6597\n",
            "Epoch 28/500\n",
            "█████████ 0.0924s - loss: 0.5467 - acc: 0.7847 - val_loss: 0.6786 - val_acc: 0.6528\n",
            "Epoch 29/500\n",
            "█████████ 0.0768s - loss: 0.6442 - acc: 0.7847 - val_loss: 0.7440 - val_acc: 0.6771\n",
            "Epoch 30/500\n",
            "█████████ 0.0763s - loss: 0.5088 - acc: 0.7882 - val_loss: 0.7066 - val_acc: 0.6701\n",
            "Epoch 31/500\n",
            "█████████ 0.0890s - loss: 0.5997 - acc: 0.8056 - val_loss: 0.5474 - val_acc: 0.6701\n",
            "Epoch 32/500\n",
            "█████████ 0.0769s - loss: 0.4744 - acc: 0.8056 - val_loss: 0.5679 - val_acc: 0.7014\n",
            "Epoch 33/500\n",
            "█████████ 0.0841s - loss: 0.4325 - acc: 0.8056 - val_loss: 0.5705 - val_acc: 0.6910\n",
            "Epoch 34/500\n",
            "█████████ 0.0787s - loss: 0.4907 - acc: 0.7951 - val_loss: 0.6275 - val_acc: 0.6701\n",
            "Epoch 35/500\n",
            "█████████ 0.0784s - loss: 0.5627 - acc: 0.8160 - val_loss: 0.9150 - val_acc: 0.6840\n",
            "Epoch 36/500\n",
            "█████████ 0.0814s - loss: 0.4473 - acc: 0.8299 - val_loss: 0.6001 - val_acc: 0.7153\n",
            "Epoch 37/500\n",
            "█████████ 0.0818s - loss: 0.5535 - acc: 0.8090 - val_loss: 0.5181 - val_acc: 0.6979\n",
            "Epoch 38/500\n",
            "█████████ 0.0919s - loss: 0.5728 - acc: 0.8056 - val_loss: 0.5508 - val_acc: 0.6806\n",
            "Epoch 39/500\n",
            "█████████ 0.0789s - loss: 0.5459 - acc: 0.8507 - val_loss: 0.6130 - val_acc: 0.7292\n",
            "Epoch 40/500\n",
            "█████████ 0.0878s - loss: 0.5621 - acc: 0.8194 - val_loss: 0.5313 - val_acc: 0.7326\n",
            "Epoch 41/500\n",
            "█████████ 0.0780s - loss: 0.4356 - acc: 0.8403 - val_loss: 0.7941 - val_acc: 0.7118\n",
            "Epoch 42/500\n",
            "█████████ 0.0894s - loss: 0.4088 - acc: 0.8368 - val_loss: 0.6372 - val_acc: 0.7014\n",
            "Epoch 43/500\n",
            "█████████ 0.0856s - loss: 0.5395 - acc: 0.8438 - val_loss: 0.6802 - val_acc: 0.7431\n",
            "Epoch 44/500\n",
            "█████████ 0.0882s - loss: 0.3711 - acc: 0.8576 - val_loss: 0.6295 - val_acc: 0.7222\n",
            "Epoch 45/500\n",
            "█████████ 0.0800s - loss: 0.4348 - acc: 0.8438 - val_loss: 0.6247 - val_acc: 0.7049\n",
            "Epoch 46/500\n",
            "█████████ 0.0975s - loss: 0.4505 - acc: 0.8403 - val_loss: 0.4039 - val_acc: 0.7118\n",
            "Epoch 47/500\n",
            "█████████ 0.0891s - loss: 0.3861 - acc: 0.8333 - val_loss: 0.5516 - val_acc: 0.6840\n",
            "Epoch 48/500\n",
            "█████████ 0.0821s - loss: 0.3033 - acc: 0.8472 - val_loss: 0.7669 - val_acc: 0.7049\n",
            "Epoch 49/500\n",
            "█████████ 0.0790s - loss: 0.4609 - acc: 0.8472 - val_loss: 0.5502 - val_acc: 0.7326\n",
            "Epoch 50/500\n",
            "█████████ 0.0795s - loss: 0.3471 - acc: 0.8333 - val_loss: 0.5520 - val_acc: 0.7188\n",
            "Epoch 51/500\n",
            "█████████ 0.0795s - loss: 0.3989 - acc: 0.8403 - val_loss: 0.5583 - val_acc: 0.7257\n",
            "Epoch 52/500\n",
            "█████████ 0.0836s - loss: 0.4869 - acc: 0.8542 - val_loss: 0.5742 - val_acc: 0.7118\n",
            "Epoch 53/500\n",
            "█████████ 0.0829s - loss: 0.3877 - acc: 0.8438 - val_loss: 0.5143 - val_acc: 0.7049\n",
            "Epoch 54/500\n",
            "█████████ 0.0942s - loss: 0.3769 - acc: 0.8611 - val_loss: 0.5774 - val_acc: 0.7222\n",
            "Epoch 55/500\n",
            "█████████ 0.0800s - loss: 0.3050 - acc: 0.8542 - val_loss: 0.4029 - val_acc: 0.7153\n",
            "Epoch 56/500\n",
            "█████████ 0.0846s - loss: 0.4670 - acc: 0.8646 - val_loss: 0.5693 - val_acc: 0.7361\n",
            "Epoch 57/500\n",
            "█████████ 0.0819s - loss: 0.4504 - acc: 0.8576 - val_loss: 0.5496 - val_acc: 0.7326\n",
            "Epoch 58/500\n",
            "█████████ 0.0819s - loss: 0.3866 - acc: 0.8576 - val_loss: 0.6964 - val_acc: 0.7431\n",
            "Epoch 59/500\n",
            "█████████ 0.0785s - loss: 0.3052 - acc: 0.8576 - val_loss: 0.5911 - val_acc: 0.7396\n",
            "Epoch 60/500\n",
            "█████████ 0.1006s - loss: 0.3875 - acc: 0.8611 - val_loss: 0.5550 - val_acc: 0.7465\n",
            "Epoch 61/500\n",
            "█████████ 0.0762s - loss: 0.3308 - acc: 0.8715 - val_loss: 0.4070 - val_acc: 0.7604\n",
            "Epoch 62/500\n",
            "█████████ 0.0769s - loss: 0.3543 - acc: 0.8681 - val_loss: 0.6108 - val_acc: 0.7431\n",
            "Epoch 63/500\n",
            "█████████ 0.0814s - loss: 0.3662 - acc: 0.8715 - val_loss: 0.4872 - val_acc: 0.7326\n",
            "Epoch 64/500\n",
            "█████████ 0.0762s - loss: 0.4133 - acc: 0.8542 - val_loss: 0.6921 - val_acc: 0.7222\n",
            "Epoch 65/500\n",
            "█████████ 0.0788s - loss: 0.3547 - acc: 0.8507 - val_loss: 0.4320 - val_acc: 0.7292\n",
            "Epoch 66/500\n",
            "█████████ 0.0803s - loss: 0.3356 - acc: 0.8715 - val_loss: 0.6283 - val_acc: 0.7292\n",
            "Epoch 67/500\n",
            "█████████ 0.0767s - loss: 0.3563 - acc: 0.8750 - val_loss: 0.4659 - val_acc: 0.7326\n",
            "Epoch 68/500\n",
            "█████████ 0.0823s - loss: 0.2478 - acc: 0.8715 - val_loss: 0.6093 - val_acc: 0.7188\n",
            "Epoch 69/500\n",
            "█████████ 0.0786s - loss: 0.2212 - acc: 0.8854 - val_loss: 0.6065 - val_acc: 0.7361\n",
            "Epoch 70/500\n",
            "█████████ 0.0883s - loss: 0.3280 - acc: 0.8681 - val_loss: 0.6903 - val_acc: 0.7257\n",
            "Epoch 71/500\n",
            "█████████ 0.0834s - loss: 0.4647 - acc: 0.8681 - val_loss: 0.6450 - val_acc: 0.7153\n",
            "Epoch 72/500\n",
            "█████████ 0.0838s - loss: 0.2527 - acc: 0.8854 - val_loss: 0.3573 - val_acc: 0.7431\n",
            "Epoch 73/500\n",
            "█████████ 0.0804s - loss: 0.4375 - acc: 0.8785 - val_loss: 0.3797 - val_acc: 0.7361\n",
            "Epoch 74/500\n",
            "█████████ 0.0789s - loss: 0.3450 - acc: 0.8750 - val_loss: 0.6247 - val_acc: 0.7431\n",
            "Epoch 75/500\n",
            "█████████ 0.0804s - loss: 0.2799 - acc: 0.8750 - val_loss: 0.4937 - val_acc: 0.7500\n",
            "Epoch 76/500\n",
            "█████████ 0.0822s - loss: 0.3586 - acc: 0.8785 - val_loss: 0.5748 - val_acc: 0.7222\n",
            "Epoch 77/500\n",
            "█████████ 0.0855s - loss: 0.3221 - acc: 0.8681 - val_loss: 0.5948 - val_acc: 0.7326\n",
            "Epoch 78/500\n",
            "█████████ 0.0835s - loss: 0.2988 - acc: 0.8785 - val_loss: 0.4707 - val_acc: 0.7778\n",
            "Epoch 79/500\n",
            "█████████ 0.0785s - loss: 0.2686 - acc: 0.8750 - val_loss: 0.6477 - val_acc: 0.7569\n",
            "Epoch 80/500\n",
            "█████████ 0.0854s - loss: 0.4161 - acc: 0.8646 - val_loss: 0.3631 - val_acc: 0.7396\n",
            "Epoch 81/500\n",
            "█████████ 0.0790s - loss: 0.2712 - acc: 0.8750 - val_loss: 0.5241 - val_acc: 0.7465\n",
            "Epoch 82/500\n",
            "█████████ 0.0807s - loss: 0.3784 - acc: 0.8750 - val_loss: 0.6975 - val_acc: 0.7326\n",
            "Epoch 83/500\n",
            "█████████ 0.0832s - loss: 0.2764 - acc: 0.8889 - val_loss: 0.4046 - val_acc: 0.7465\n",
            "Epoch 84/500\n",
            "█████████ 0.0816s - loss: 0.1522 - acc: 0.8889 - val_loss: 0.6245 - val_acc: 0.7361\n",
            "Epoch 85/500\n",
            "█████████ 0.0836s - loss: 0.3290 - acc: 0.8854 - val_loss: 0.5598 - val_acc: 0.7222\n",
            "Epoch 86/500\n",
            "█████████ 0.0867s - loss: 0.3552 - acc: 0.9062 - val_loss: 0.4243 - val_acc: 0.7326\n",
            "Epoch 87/500\n",
            "█████████ 0.0825s - loss: 0.1988 - acc: 0.9097 - val_loss: 0.4996 - val_acc: 0.7465\n",
            "Epoch 88/500\n",
            "█████████ 0.0869s - loss: 0.2593 - acc: 0.8924 - val_loss: 0.6184 - val_acc: 0.7396\n",
            "Epoch 89/500\n",
            "█████████ 0.0912s - loss: 0.4677 - acc: 0.8819 - val_loss: 0.6185 - val_acc: 0.7396\n",
            "Epoch 90/500\n",
            "█████████ 0.0836s - loss: 0.3407 - acc: 0.8889 - val_loss: 0.4825 - val_acc: 0.7604\n",
            "Epoch 91/500\n",
            "█████████ 0.1003s - loss: 0.3099 - acc: 0.8993 - val_loss: 0.5095 - val_acc: 0.7326\n",
            "Epoch 92/500\n",
            "█████████ 0.0820s - loss: 0.3085 - acc: 0.8819 - val_loss: 0.3927 - val_acc: 0.7465\n",
            "Epoch 93/500\n",
            "█████████ 0.0835s - loss: 0.3044 - acc: 0.8924 - val_loss: 0.8354 - val_acc: 0.7500\n",
            "Epoch 94/500\n",
            "█████████ 0.0811s - loss: 0.3081 - acc: 0.8924 - val_loss: 0.6302 - val_acc: 0.7465\n",
            "Epoch 95/500\n",
            "█████████ 0.0921s - loss: 0.1775 - acc: 0.9062 - val_loss: 0.5373 - val_acc: 0.7500\n",
            "Epoch 96/500\n",
            "█████████ 0.0822s - loss: 0.3243 - acc: 0.8958 - val_loss: 0.5586 - val_acc: 0.7708\n",
            "Epoch 97/500\n",
            "█████████ 0.0794s - loss: 0.2232 - acc: 0.8785 - val_loss: 0.5380 - val_acc: 0.7292\n",
            "Epoch 98/500\n",
            "█████████ 0.0772s - loss: 0.1884 - acc: 0.8924 - val_loss: 0.4816 - val_acc: 0.7431\n",
            "Epoch 99/500\n",
            "█████████ 0.0826s - loss: 0.2241 - acc: 0.9062 - val_loss: 0.4197 - val_acc: 0.7431\n",
            "Epoch 100/500\n",
            "█████████ 0.0777s - loss: 0.2758 - acc: 0.9167 - val_loss: 0.5524 - val_acc: 0.7604\n",
            "Epoch 101/500\n",
            "█████████ 0.0828s - loss: 0.2815 - acc: 0.8924 - val_loss: 0.3576 - val_acc: 0.7465\n",
            "Epoch 102/500\n",
            "█████████ 0.0787s - loss: 0.1690 - acc: 0.8993 - val_loss: 0.4635 - val_acc: 0.7535\n",
            "Epoch 103/500\n",
            "█████████ 0.0867s - loss: 0.3149 - acc: 0.9062 - val_loss: 0.5728 - val_acc: 0.7743\n",
            "Epoch 104/500\n",
            "█████████ 0.0835s - loss: 0.1700 - acc: 0.8958 - val_loss: 0.5661 - val_acc: 0.7708\n",
            "Epoch 105/500\n",
            "█████████ 0.0809s - loss: 0.3844 - acc: 0.9028 - val_loss: 0.6603 - val_acc: 0.7604\n",
            "Epoch 106/500\n",
            "█████████ 0.0813s - loss: 0.4176 - acc: 0.8924 - val_loss: 0.6117 - val_acc: 0.7431\n",
            "Epoch 107/500\n",
            "█████████ 0.0887s - loss: 0.2143 - acc: 0.9097 - val_loss: 0.5908 - val_acc: 0.7674\n",
            "Epoch 108/500\n",
            "█████████ 0.0807s - loss: 0.2556 - acc: 0.9028 - val_loss: 0.6142 - val_acc: 0.7847\n",
            "Epoch 109/500\n",
            "█████████ 0.0818s - loss: 0.3047 - acc: 0.9167 - val_loss: 0.5616 - val_acc: 0.7569\n",
            "Epoch 110/500\n",
            "█████████ 0.0815s - loss: 0.2660 - acc: 0.9028 - val_loss: 0.5362 - val_acc: 0.7743\n",
            "Epoch 111/500\n",
            "█████████ 0.0802s - loss: 0.1389 - acc: 0.8889 - val_loss: 0.5521 - val_acc: 0.7743\n",
            "Epoch 112/500\n",
            "█████████ 0.0769s - loss: 0.1763 - acc: 0.8889 - val_loss: 0.6589 - val_acc: 0.7812\n",
            "Epoch 113/500\n",
            "█████████ 0.0829s - loss: 0.2431 - acc: 0.8958 - val_loss: 0.9166 - val_acc: 0.7604\n",
            "Epoch 114/500\n",
            "█████████ 0.0770s - loss: 0.2247 - acc: 0.8993 - val_loss: 0.5890 - val_acc: 0.7882\n",
            "Epoch 115/500\n",
            "█████████ 0.0898s - loss: 0.3837 - acc: 0.9167 - val_loss: 0.6093 - val_acc: 0.7778\n",
            "Epoch 116/500\n",
            "█████████ 0.0789s - loss: 0.4055 - acc: 0.8819 - val_loss: 0.4581 - val_acc: 0.7604\n",
            "Epoch 117/500\n",
            "█████████ 0.0817s - loss: 0.2708 - acc: 0.8889 - val_loss: 0.4939 - val_acc: 0.7639\n",
            "Epoch 118/500\n",
            "█████████ 0.0811s - loss: 0.3196 - acc: 0.8958 - val_loss: 0.4480 - val_acc: 0.7743\n",
            "Epoch 119/500\n",
            "█████████ 0.0803s - loss: 0.3056 - acc: 0.9167 - val_loss: 0.3779 - val_acc: 0.7639\n",
            "Epoch 120/500\n",
            "█████████ 0.0786s - loss: 0.1809 - acc: 0.9201 - val_loss: 0.5748 - val_acc: 0.7743\n",
            "Epoch 121/500\n",
            "█████████ 0.0823s - loss: 0.1859 - acc: 0.8854 - val_loss: 0.7038 - val_acc: 0.7604\n",
            "Epoch 122/500\n",
            "█████████ 0.0795s - loss: 0.1737 - acc: 0.8993 - val_loss: 0.4142 - val_acc: 0.7639\n",
            "Epoch 123/500\n",
            "█████████ 0.0799s - loss: 0.2820 - acc: 0.9062 - val_loss: 0.6005 - val_acc: 0.7639\n",
            "Epoch 124/500\n",
            "█████████ 0.0780s - loss: 0.1252 - acc: 0.9271 - val_loss: 0.6061 - val_acc: 0.7569\n",
            "Epoch 125/500\n",
            "█████████ 0.0830s - loss: 0.3273 - acc: 0.9271 - val_loss: 0.5423 - val_acc: 0.7639\n",
            "Epoch 126/500\n",
            "█████████ 0.0776s - loss: 0.2766 - acc: 0.9132 - val_loss: 0.3182 - val_acc: 0.7604\n",
            "Epoch 127/500\n",
            "█████████ 0.0848s - loss: 0.2465 - acc: 0.9028 - val_loss: 0.4396 - val_acc: 0.7569\n",
            "Epoch 128/500\n",
            "█████████ 0.0796s - loss: 0.1929 - acc: 0.9236 - val_loss: 0.4215 - val_acc: 0.7847\n",
            "Epoch 129/500\n",
            "█████████ 0.0866s - loss: 0.1368 - acc: 0.9097 - val_loss: 0.4559 - val_acc: 0.7674\n",
            "Epoch 130/500\n",
            "█████████ 0.0788s - loss: 0.2156 - acc: 0.9097 - val_loss: 0.5907 - val_acc: 0.7708\n",
            "Epoch 131/500\n",
            "█████████ 0.0799s - loss: 0.1952 - acc: 0.9167 - val_loss: 0.6048 - val_acc: 0.7708\n",
            "Epoch 132/500\n",
            "█████████ 0.0844s - loss: 0.3262 - acc: 0.9271 - val_loss: 0.6262 - val_acc: 0.7708\n",
            "Epoch 133/500\n",
            "█████████ 0.0824s - loss: 0.2783 - acc: 0.9340 - val_loss: 0.7767 - val_acc: 0.7778\n",
            "Epoch 134/500\n",
            "█████████ 0.0961s - loss: 0.1275 - acc: 0.9201 - val_loss: 0.6602 - val_acc: 0.7535\n",
            "Epoch 135/500\n",
            "█████████ 0.0815s - loss: 0.1662 - acc: 0.9236 - val_loss: 0.6481 - val_acc: 0.7708\n",
            "Epoch 136/500\n",
            "█████████ 0.0840s - loss: 0.1921 - acc: 0.9236 - val_loss: 0.6025 - val_acc: 0.7951\n",
            "Epoch 137/500\n",
            "█████████ 0.0889s - loss: 0.2783 - acc: 0.9340 - val_loss: 0.4877 - val_acc: 0.7812\n",
            "Epoch 138/500\n",
            "█████████ 0.0837s - loss: 0.3167 - acc: 0.9340 - val_loss: 0.5667 - val_acc: 0.7639\n",
            "Epoch 139/500\n",
            "█████████ 0.0816s - loss: 0.1442 - acc: 0.9201 - val_loss: 0.2807 - val_acc: 0.7812\n",
            "Epoch 140/500\n",
            "█████████ 0.0812s - loss: 0.2850 - acc: 0.9167 - val_loss: 0.3947 - val_acc: 0.7847\n",
            "Epoch 141/500\n",
            "█████████ 0.0814s - loss: 0.1973 - acc: 0.9132 - val_loss: 0.5141 - val_acc: 0.7674\n",
            "Epoch 142/500\n",
            "█████████ 0.0813s - loss: 0.1372 - acc: 0.9236 - val_loss: 0.6527 - val_acc: 0.7708\n",
            "Epoch 143/500\n",
            "█████████ 0.0852s - loss: 0.2407 - acc: 0.9340 - val_loss: 0.3834 - val_acc: 0.7674\n",
            "Epoch 144/500\n",
            "█████████ 0.0816s - loss: 0.2168 - acc: 0.9306 - val_loss: 0.5854 - val_acc: 0.7708\n",
            "Epoch 145/500\n",
            "█████████ 0.0810s - loss: 0.1852 - acc: 0.9410 - val_loss: 0.2746 - val_acc: 0.7743\n",
            "Epoch 146/500\n",
            "█████████ 0.0846s - loss: 0.1404 - acc: 0.9271 - val_loss: 0.5925 - val_acc: 0.7812\n",
            "Epoch 147/500\n",
            "█████████ 0.0820s - loss: 0.1782 - acc: 0.9028 - val_loss: 0.4644 - val_acc: 0.7639\n",
            "Epoch 148/500\n",
            "█████████ 0.0843s - loss: 0.1506 - acc: 0.9201 - val_loss: 0.5560 - val_acc: 0.7639\n",
            "Epoch 149/500\n",
            "█████████ 0.0854s - loss: 0.2468 - acc: 0.9410 - val_loss: 0.6171 - val_acc: 0.7639\n",
            "Epoch 150/500\n",
            "█████████ 0.0819s - loss: 0.1142 - acc: 0.9375 - val_loss: 0.6361 - val_acc: 0.7465\n",
            "Epoch 151/500\n",
            "█████████ 0.0877s - loss: 0.1270 - acc: 0.9306 - val_loss: 0.4754 - val_acc: 0.7674\n",
            "Epoch 152/500\n",
            "█████████ 0.0814s - loss: 0.1647 - acc: 0.9306 - val_loss: 0.5450 - val_acc: 0.7743\n",
            "Epoch 153/500\n",
            "█████████ 0.0825s - loss: 0.2044 - acc: 0.9375 - val_loss: 0.8050 - val_acc: 0.7674\n",
            "Epoch 154/500\n",
            "█████████ 0.0828s - loss: 0.2056 - acc: 0.9479 - val_loss: 0.7878 - val_acc: 0.7847\n",
            "Epoch 155/500\n",
            "█████████ 0.0818s - loss: 0.2259 - acc: 0.9444 - val_loss: 0.5611 - val_acc: 0.7882\n",
            "Epoch 156/500\n",
            "█████████ 0.0841s - loss: 0.1834 - acc: 0.9236 - val_loss: 0.5886 - val_acc: 0.7639\n",
            "Epoch 157/500\n",
            "█████████ 0.0771s - loss: 0.0912 - acc: 0.9375 - val_loss: 0.3255 - val_acc: 0.7778\n",
            "Epoch 158/500\n",
            "█████████ 0.0899s - loss: 0.1545 - acc: 0.9340 - val_loss: 0.5892 - val_acc: 0.7847\n",
            "Epoch 159/500\n",
            "█████████ 0.0748s - loss: 0.1833 - acc: 0.9132 - val_loss: 0.4648 - val_acc: 0.7847\n",
            "Epoch 160/500\n",
            "█████████ 0.0825s - loss: 0.2559 - acc: 0.9410 - val_loss: 0.8294 - val_acc: 0.7604\n",
            "Epoch 161/500\n",
            "█████████ 0.0755s - loss: 0.1643 - acc: 0.9479 - val_loss: 0.5193 - val_acc: 0.7847\n",
            "Epoch 162/500\n",
            "█████████ 0.0808s - loss: 0.1597 - acc: 0.9375 - val_loss: 0.4570 - val_acc: 0.7882\n",
            "Epoch 163/500\n",
            "█████████ 0.0853s - loss: 0.1444 - acc: 0.9514 - val_loss: 0.7944 - val_acc: 0.7917\n",
            "Epoch 164/500\n",
            "█████████ 0.0787s - loss: 0.2400 - acc: 0.9479 - val_loss: 0.6843 - val_acc: 0.7674\n",
            "Epoch 165/500\n",
            "█████████ 0.0856s - loss: 0.1911 - acc: 0.9444 - val_loss: 0.3928 - val_acc: 0.7569\n",
            "Epoch 166/500\n",
            "█████████ 0.0795s - loss: 0.1570 - acc: 0.9410 - val_loss: 0.5233 - val_acc: 0.7778\n",
            "Epoch 167/500\n",
            "█████████ 0.0846s - loss: 0.1651 - acc: 0.9618 - val_loss: 0.3724 - val_acc: 0.7778\n",
            "Epoch 168/500\n",
            "█████████ 0.0833s - loss: 0.1331 - acc: 0.9306 - val_loss: 0.5709 - val_acc: 0.7500\n",
            "Epoch 169/500\n",
            "█████████ 0.0868s - loss: 0.1581 - acc: 0.9375 - val_loss: 0.5095 - val_acc: 0.7708\n",
            "Epoch 170/500\n",
            "█████████ 0.0848s - loss: 0.1731 - acc: 0.9444 - val_loss: 0.5511 - val_acc: 0.7778\n",
            "Epoch 171/500\n",
            "█████████ 0.0813s - loss: 0.1319 - acc: 0.9375 - val_loss: 0.5367 - val_acc: 0.7847\n",
            "Epoch 172/500\n",
            "█████████ 0.0832s - loss: 0.2424 - acc: 0.9236 - val_loss: 0.4939 - val_acc: 0.7743\n",
            "Epoch 173/500\n",
            "█████████ 0.0821s - loss: 0.2462 - acc: 0.9306 - val_loss: 0.4373 - val_acc: 0.7674\n",
            "Epoch 174/500\n",
            "█████████ 0.0806s - loss: 0.1414 - acc: 0.9410 - val_loss: 0.2576 - val_acc: 0.7778\n",
            "Epoch 175/500\n",
            "█████████ 0.0854s - loss: 0.1238 - acc: 0.9514 - val_loss: 0.7012 - val_acc: 0.7569\n",
            "Epoch 176/500\n",
            "█████████ 0.0785s - loss: 0.0767 - acc: 0.9514 - val_loss: 0.4054 - val_acc: 0.7535\n",
            "Epoch 177/500\n",
            "█████████ 0.0868s - loss: 0.1896 - acc: 0.9444 - val_loss: 0.5287 - val_acc: 0.7708\n",
            "Epoch 178/500\n",
            "█████████ 0.0833s - loss: 0.2350 - acc: 0.9375 - val_loss: 0.4504 - val_acc: 0.7569\n",
            "Epoch 179/500\n",
            "█████████ 0.0863s - loss: 0.1754 - acc: 0.9410 - val_loss: 0.7348 - val_acc: 0.7326\n",
            "Epoch 180/500\n",
            "█████████ 0.0852s - loss: 0.1969 - acc: 0.9375 - val_loss: 0.6394 - val_acc: 0.7431\n",
            "Epoch 181/500\n",
            "█████████ 0.0834s - loss: 0.1610 - acc: 0.9340 - val_loss: 0.3540 - val_acc: 0.7639\n",
            "Epoch 182/500\n",
            "█████████ 0.0823s - loss: 0.2243 - acc: 0.9514 - val_loss: 0.4397 - val_acc: 0.7604\n",
            "Epoch 183/500\n",
            "█████████ 0.0818s - loss: 0.1939 - acc: 0.9479 - val_loss: 0.5595 - val_acc: 0.7639\n",
            "Epoch 184/500\n",
            "█████████ 0.0860s - loss: 0.1541 - acc: 0.9271 - val_loss: 0.2085 - val_acc: 0.7431\n",
            "Epoch 185/500\n",
            "█████████ 0.0803s - loss: 0.1839 - acc: 0.9375 - val_loss: 0.4648 - val_acc: 0.7431\n",
            "Epoch 186/500\n",
            "█████████ 0.0808s - loss: 0.2715 - acc: 0.9444 - val_loss: 0.5069 - val_acc: 0.7639\n",
            "Epoch 187/500\n",
            "█████████ 0.0823s - loss: 0.1788 - acc: 0.9444 - val_loss: 0.6261 - val_acc: 0.7639\n",
            "Epoch 188/500\n",
            "█████████ 0.0815s - loss: 0.1758 - acc: 0.9618 - val_loss: 0.4071 - val_acc: 0.7778\n",
            "Epoch 189/500\n",
            "█████████ 0.0866s - loss: 0.1277 - acc: 0.9444 - val_loss: 0.6714 - val_acc: 0.7535\n",
            "Epoch 190/500\n",
            "█████████ 0.0847s - loss: 0.1899 - acc: 0.9410 - val_loss: 0.4523 - val_acc: 0.7778\n",
            "Epoch 191/500\n",
            "█████████ 0.0893s - loss: 0.1281 - acc: 0.9826 - val_loss: 0.4914 - val_acc: 0.7743\n",
            "Epoch 192/500\n",
            "█████████ 0.0870s - loss: 0.1053 - acc: 0.9757 - val_loss: 0.7581 - val_acc: 0.7639\n",
            "Epoch 193/500\n",
            "█████████ 0.0981s - loss: 0.0778 - acc: 0.9444 - val_loss: 0.4631 - val_acc: 0.7639\n",
            "Epoch 194/500\n",
            "█████████ 0.0917s - loss: 0.1544 - acc: 0.9583 - val_loss: 0.5180 - val_acc: 0.7812\n",
            "Epoch 195/500\n",
            "█████████ 0.0789s - loss: 0.1268 - acc: 0.9618 - val_loss: 0.6291 - val_acc: 0.7778\n",
            "Epoch 196/500\n",
            "█████████ 0.0794s - loss: 0.1836 - acc: 0.9479 - val_loss: 0.5285 - val_acc: 0.7674\n",
            "Epoch 197/500\n",
            "█████████ 0.0818s - loss: 0.1385 - acc: 0.9618 - val_loss: 0.5714 - val_acc: 0.7396\n",
            "Epoch 198/500\n",
            "█████████ 0.0849s - loss: 0.1992 - acc: 0.9583 - val_loss: 0.6497 - val_acc: 0.7639\n",
            "Epoch 199/500\n",
            "█████████ 0.0832s - loss: 0.0972 - acc: 0.9444 - val_loss: 0.6891 - val_acc: 0.7535\n",
            "Epoch 200/500\n",
            "█████████ 0.0818s - loss: 0.1108 - acc: 0.9479 - val_loss: 0.5437 - val_acc: 0.7535\n",
            "Epoch 201/500\n",
            "█████████ 0.0824s - loss: 0.1103 - acc: 0.9549 - val_loss: 0.4621 - val_acc: 0.7917\n",
            "Epoch 202/500\n",
            "█████████ 0.0823s - loss: 0.1032 - acc: 0.9722 - val_loss: 0.5124 - val_acc: 0.7882\n",
            "Epoch 203/500\n",
            "█████████ 0.0828s - loss: 0.2319 - acc: 0.9583 - val_loss: 0.8045 - val_acc: 0.7778\n",
            "Epoch 204/500\n",
            "█████████ 0.0804s - loss: 0.1820 - acc: 0.9653 - val_loss: 0.6330 - val_acc: 0.7743\n",
            "Epoch 205/500\n",
            "█████████ 0.0851s - loss: 0.1513 - acc: 0.9757 - val_loss: 0.3927 - val_acc: 0.7917\n",
            "Epoch 206/500\n",
            "█████████ 0.0858s - loss: 0.0677 - acc: 0.9861 - val_loss: 0.4161 - val_acc: 0.7743\n",
            "Epoch 207/500\n",
            "█████████ 0.0835s - loss: 0.1489 - acc: 0.9688 - val_loss: 0.4325 - val_acc: 0.7674\n",
            "Epoch 208/500\n",
            "█████████ 0.0771s - loss: 0.1959 - acc: 0.9583 - val_loss: 0.2637 - val_acc: 0.7882\n",
            "Epoch 209/500\n",
            "█████████ 0.0838s - loss: 0.1053 - acc: 0.9583 - val_loss: 0.4116 - val_acc: 0.7708\n",
            "Epoch 210/500\n",
            "█████████ 0.0817s - loss: 0.0969 - acc: 0.9757 - val_loss: 0.3637 - val_acc: 0.7674\n",
            "Epoch 211/500\n",
            "█████████ 0.0808s - loss: 0.0701 - acc: 0.9688 - val_loss: 0.6438 - val_acc: 0.8021\n",
            "Epoch 212/500\n",
            "█████████ 0.0885s - loss: 0.1333 - acc: 0.9826 - val_loss: 0.4043 - val_acc: 0.7917\n",
            "Epoch 213/500\n",
            "█████████ 0.0813s - loss: 0.1583 - acc: 0.9722 - val_loss: 0.4755 - val_acc: 0.7708\n",
            "Epoch 214/500\n",
            "█████████ 0.0816s - loss: 0.1222 - acc: 0.9688 - val_loss: 0.4472 - val_acc: 0.7743\n",
            "Epoch 215/500\n",
            "█████████ 0.0806s - loss: 0.1854 - acc: 0.9479 - val_loss: 0.6042 - val_acc: 0.7708\n",
            "Epoch 216/500\n",
            "█████████ 0.0853s - loss: 0.1024 - acc: 0.9618 - val_loss: 0.6832 - val_acc: 0.7708\n",
            "Epoch 217/500\n",
            "█████████ 0.0797s - loss: 0.1677 - acc: 0.9653 - val_loss: 0.5779 - val_acc: 0.7604\n",
            "Epoch 218/500\n",
            "█████████ 0.0821s - loss: 0.1227 - acc: 0.9688 - val_loss: 0.6494 - val_acc: 0.7604\n",
            "Epoch 219/500\n",
            "█████████ 0.0811s - loss: 0.1213 - acc: 0.9688 - val_loss: 0.7101 - val_acc: 0.7361\n",
            "Epoch 220/500\n",
            "█████████ 0.0858s - loss: 0.1152 - acc: 0.9757 - val_loss: 0.3985 - val_acc: 0.7708\n",
            "Epoch 221/500\n",
            "█████████ 0.0852s - loss: 0.1004 - acc: 0.9688 - val_loss: 0.6681 - val_acc: 0.7604\n",
            "Epoch 222/500\n",
            "█████████ 0.0824s - loss: 0.1441 - acc: 0.9688 - val_loss: 0.6353 - val_acc: 0.7604\n",
            "Epoch 223/500\n",
            "█████████ 0.0833s - loss: 0.1431 - acc: 0.9653 - val_loss: 0.4704 - val_acc: 0.7743\n",
            "Epoch 224/500\n",
            "█████████ 0.0825s - loss: 0.1269 - acc: 0.9514 - val_loss: 0.5565 - val_acc: 0.7535\n",
            "Epoch 225/500\n",
            "█████████ 0.0810s - loss: 0.0853 - acc: 0.9688 - val_loss: 0.4601 - val_acc: 0.7500\n",
            "Epoch 226/500\n",
            "█████████ 0.0816s - loss: 0.1443 - acc: 0.9688 - val_loss: 0.4685 - val_acc: 0.7604\n",
            "Epoch 227/500\n",
            "█████████ 0.0790s - loss: 0.0978 - acc: 0.9722 - val_loss: 0.6162 - val_acc: 0.7674\n",
            "Epoch 228/500\n",
            "█████████ 0.0852s - loss: 0.0844 - acc: 0.9688 - val_loss: 0.3757 - val_acc: 0.7708\n",
            "Epoch 229/500\n",
            "█████████ 0.0817s - loss: 0.1421 - acc: 0.9722 - val_loss: 0.6031 - val_acc: 0.7569\n",
            "Epoch 230/500\n",
            "█████████ 0.0834s - loss: 0.1597 - acc: 0.9653 - val_loss: 0.3567 - val_acc: 0.7500\n",
            "Epoch 231/500\n",
            "█████████ 0.0805s - loss: 0.0615 - acc: 0.9688 - val_loss: 0.4402 - val_acc: 0.7674\n",
            "Epoch 232/500\n",
            "█████████ 0.0824s - loss: 0.1621 - acc: 0.9722 - val_loss: 0.6705 - val_acc: 0.7569\n",
            "Epoch 233/500\n",
            "█████████ 0.0822s - loss: 0.1004 - acc: 0.9722 - val_loss: 0.5984 - val_acc: 0.7812\n",
            "Epoch 234/500\n",
            "█████████ 0.0881s - loss: 0.1351 - acc: 0.9792 - val_loss: 0.5141 - val_acc: 0.7778\n",
            "Epoch 235/500\n",
            "█████████ 0.0769s - loss: 0.1175 - acc: 0.9792 - val_loss: 0.5951 - val_acc: 0.7778\n",
            "Epoch 236/500\n",
            "█████████ 0.0800s - loss: 0.0483 - acc: 0.9792 - val_loss: 0.7223 - val_acc: 0.7639\n",
            "Epoch 237/500\n",
            "█████████ 0.0826s - loss: 0.1055 - acc: 0.9757 - val_loss: 0.4601 - val_acc: 0.7812\n",
            "Epoch 238/500\n",
            "█████████ 0.0789s - loss: 0.1282 - acc: 0.9792 - val_loss: 0.4898 - val_acc: 0.7743\n",
            "Epoch 239/500\n",
            "█████████ 0.0788s - loss: 0.1480 - acc: 0.9757 - val_loss: 0.6524 - val_acc: 0.7812\n",
            "Epoch 240/500\n",
            "█████████ 0.0785s - loss: 0.0802 - acc: 0.9826 - val_loss: 0.5330 - val_acc: 0.7639\n",
            "Epoch 241/500\n",
            "█████████ 0.0845s - loss: 0.1415 - acc: 0.9792 - val_loss: 0.4179 - val_acc: 0.7569\n",
            "Epoch 242/500\n",
            "█████████ 0.0850s - loss: 0.0575 - acc: 0.9861 - val_loss: 0.6462 - val_acc: 0.7778\n",
            "Epoch 243/500\n",
            "█████████ 0.0840s - loss: 0.0778 - acc: 0.9757 - val_loss: 0.5885 - val_acc: 0.7604\n",
            "Epoch 244/500\n",
            "█████████ 0.0881s - loss: 0.0803 - acc: 0.9618 - val_loss: 1.0219 - val_acc: 0.7604\n",
            "Epoch 245/500\n",
            "█████████ 0.0876s - loss: 0.1042 - acc: 0.9722 - val_loss: 0.5394 - val_acc: 0.7639\n",
            "Epoch 246/500\n",
            "█████████ 0.0866s - loss: 0.2235 - acc: 0.9757 - val_loss: 0.7124 - val_acc: 0.7535\n",
            "Epoch 247/500\n",
            "█████████ 0.0799s - loss: 0.0898 - acc: 0.9722 - val_loss: 0.6889 - val_acc: 0.7604\n",
            "Epoch 248/500\n",
            "█████████ 0.0894s - loss: 0.0629 - acc: 0.9931 - val_loss: 0.7073 - val_acc: 0.7778\n",
            "Epoch 249/500\n",
            "█████████ 0.0799s - loss: 0.1215 - acc: 0.9861 - val_loss: 0.7997 - val_acc: 0.7743\n",
            "Epoch 250/500\n",
            "█████████ 0.0871s - loss: 0.1598 - acc: 0.9861 - val_loss: 0.4856 - val_acc: 0.7778\n",
            "Epoch 251/500\n",
            "█████████ 0.0823s - loss: 0.1011 - acc: 0.9931 - val_loss: 0.4783 - val_acc: 0.7847\n",
            "Epoch 252/500\n",
            "█████████ 0.0841s - loss: 0.0655 - acc: 0.9861 - val_loss: 0.4939 - val_acc: 0.7604\n",
            "Epoch 253/500\n",
            "█████████ 0.0857s - loss: 0.1171 - acc: 0.9792 - val_loss: 0.4249 - val_acc: 0.7500\n",
            "Epoch 254/500\n",
            "█████████ 0.0788s - loss: 0.0890 - acc: 0.9618 - val_loss: 0.3842 - val_acc: 0.7535\n",
            "Epoch 255/500\n",
            "█████████ 0.0817s - loss: 0.0665 - acc: 0.9826 - val_loss: 0.5909 - val_acc: 0.7743\n",
            "Epoch 256/500\n",
            "█████████ 0.0810s - loss: 0.0346 - acc: 0.9896 - val_loss: 0.7008 - val_acc: 0.7778\n",
            "Epoch 257/500\n",
            "█████████ 0.0794s - loss: 0.1053 - acc: 0.9861 - val_loss: 0.6462 - val_acc: 0.7708\n",
            "Epoch 258/500\n",
            "█████████ 0.0868s - loss: 0.0612 - acc: 0.9861 - val_loss: 0.7807 - val_acc: 0.7812\n",
            "Epoch 259/500\n",
            "█████████ 0.0829s - loss: 0.0904 - acc: 0.9896 - val_loss: 0.4600 - val_acc: 0.7639\n",
            "Epoch 260/500\n",
            "█████████ 0.0859s - loss: 0.0897 - acc: 0.9757 - val_loss: 0.7495 - val_acc: 0.7743\n",
            "Epoch 261/500\n",
            "█████████ 0.0762s - loss: 0.1065 - acc: 0.9653 - val_loss: 0.7803 - val_acc: 0.7500\n",
            "Epoch 262/500\n",
            "█████████ 0.0772s - loss: 0.1195 - acc: 0.9861 - val_loss: 0.9585 - val_acc: 0.7569\n",
            "Epoch 263/500\n",
            "█████████ 0.0826s - loss: 0.0603 - acc: 0.9931 - val_loss: 0.4176 - val_acc: 0.7639\n",
            "Epoch 264/500\n",
            "█████████ 0.0803s - loss: 0.0715 - acc: 0.9931 - val_loss: 0.5226 - val_acc: 0.7812\n",
            "Epoch 265/500\n",
            "█████████ 0.0813s - loss: 0.0578 - acc: 0.9931 - val_loss: 0.5610 - val_acc: 0.7639\n",
            "Epoch 266/500\n",
            "█████████ 0.0825s - loss: 0.1101 - acc: 0.9792 - val_loss: 0.6058 - val_acc: 0.7569\n",
            "Epoch 267/500\n",
            "█████████ 0.0791s - loss: 0.0546 - acc: 0.9896 - val_loss: 0.5546 - val_acc: 0.7569\n",
            "Epoch 268/500\n",
            "█████████ 0.0769s - loss: 0.0801 - acc: 0.9896 - val_loss: 0.6007 - val_acc: 0.7639\n",
            "Epoch 269/500\n",
            "█████████ 0.0839s - loss: 0.0577 - acc: 0.9896 - val_loss: 0.5934 - val_acc: 0.7708\n",
            "Epoch 270/500\n",
            "█████████ 0.0801s - loss: 0.0520 - acc: 0.9965 - val_loss: 0.3545 - val_acc: 0.7639\n",
            "Epoch 271/500\n",
            "█████████ 0.0794s - loss: 0.0742 - acc: 0.9965 - val_loss: 0.8403 - val_acc: 0.7535\n",
            "Epoch 272/500\n",
            "█████████ 0.0818s - loss: 0.0629 - acc: 0.9792 - val_loss: 0.3788 - val_acc: 0.7604\n",
            "Epoch 273/500\n",
            "█████████ 0.0804s - loss: 0.0967 - acc: 0.9653 - val_loss: 0.8081 - val_acc: 0.7535\n",
            "Epoch 274/500\n",
            "█████████ 0.0901s - loss: 0.0759 - acc: 0.9757 - val_loss: 0.6523 - val_acc: 0.7396\n",
            "Epoch 275/500\n",
            "█████████ 0.0802s - loss: 0.0653 - acc: 0.9861 - val_loss: 0.3667 - val_acc: 0.7292\n",
            "Epoch 276/500\n",
            "█████████ 0.0848s - loss: 0.0443 - acc: 0.9965 - val_loss: 0.8484 - val_acc: 0.7535\n",
            "Epoch 277/500\n",
            "█████████ 0.0802s - loss: 0.1250 - acc: 0.9965 - val_loss: 0.6483 - val_acc: 0.7674\n",
            "Epoch 278/500\n",
            "█████████ 0.0761s - loss: 0.0670 - acc: 0.9931 - val_loss: 0.5515 - val_acc: 0.7639\n",
            "Epoch 279/500\n",
            "█████████ 0.0788s - loss: 0.1284 - acc: 0.9826 - val_loss: 0.6955 - val_acc: 0.7500\n",
            "Epoch 280/500\n",
            "█████████ 0.0771s - loss: 0.0992 - acc: 0.9722 - val_loss: 0.3602 - val_acc: 0.7743\n",
            "Epoch 281/500\n",
            "█████████ 0.0856s - loss: 0.1410 - acc: 0.9896 - val_loss: 0.5531 - val_acc: 0.7639\n",
            "Epoch 282/500\n",
            "█████████ 0.0799s - loss: 0.0385 - acc: 0.9931 - val_loss: 0.3955 - val_acc: 0.7569\n",
            "Epoch 283/500\n",
            "█████████ 0.0888s - loss: 0.1467 - acc: 0.9722 - val_loss: 0.2239 - val_acc: 0.7569\n",
            "Epoch 284/500\n",
            "█████████ 0.0796s - loss: 0.0833 - acc: 0.9931 - val_loss: 0.6589 - val_acc: 0.7639\n",
            "Epoch 285/500\n",
            "█████████ 0.0792s - loss: 0.0499 - acc: 0.9931 - val_loss: 0.5227 - val_acc: 0.7743\n",
            "Epoch 286/500\n",
            "█████████ 0.0779s - loss: 0.0625 - acc: 0.9861 - val_loss: 0.7581 - val_acc: 0.7431\n",
            "Epoch 287/500\n",
            "█████████ 0.0809s - loss: 0.0568 - acc: 0.9826 - val_loss: 0.7561 - val_acc: 0.7604\n",
            "Epoch 288/500\n",
            "█████████ 0.0925s - loss: 0.0829 - acc: 0.9931 - val_loss: 0.3642 - val_acc: 0.7639\n",
            "Epoch 289/500\n",
            "█████████ 0.0797s - loss: 0.0926 - acc: 0.9826 - val_loss: 0.5097 - val_acc: 0.7778\n",
            "Epoch 290/500\n",
            "█████████ 0.0842s - loss: 0.0808 - acc: 0.9826 - val_loss: 0.4303 - val_acc: 0.7535\n",
            "Epoch 291/500\n",
            "█████████ 0.0857s - loss: 0.0814 - acc: 0.9931 - val_loss: 1.4272 - val_acc: 0.7500\n",
            "Epoch 292/500\n",
            "█████████ 0.0784s - loss: 0.0630 - acc: 0.9965 - val_loss: 0.6409 - val_acc: 0.7326\n",
            "Epoch 293/500\n",
            "█████████ 0.0809s - loss: 0.0512 - acc: 0.9896 - val_loss: 0.5771 - val_acc: 0.7604\n",
            "Epoch 294/500\n",
            "█████████ 0.0791s - loss: 0.0821 - acc: 0.9931 - val_loss: 0.1257 - val_acc: 0.7569\n",
            "Epoch 295/500\n",
            "█████████ 0.0801s - loss: 0.0590 - acc: 0.9826 - val_loss: 0.6967 - val_acc: 0.7431\n",
            "Epoch 296/500\n",
            "█████████ 0.0811s - loss: 0.0869 - acc: 0.9757 - val_loss: 0.9002 - val_acc: 0.7465\n",
            "Epoch 297/500\n",
            "█████████ 0.0852s - loss: 0.0999 - acc: 0.9757 - val_loss: 0.9803 - val_acc: 0.7569\n",
            "Epoch 298/500\n",
            "█████████ 0.0937s - loss: 0.0410 - acc: 0.9896 - val_loss: 0.5640 - val_acc: 0.7465\n",
            "Epoch 299/500\n",
            "█████████ 0.0905s - loss: 0.1046 - acc: 0.9931 - val_loss: 0.6055 - val_acc: 0.7396\n",
            "Epoch 300/500\n",
            "█████████ 0.0853s - loss: 0.0764 - acc: 0.9931 - val_loss: 0.6444 - val_acc: 0.7604\n",
            "Epoch 301/500\n",
            "█████████ 0.0839s - loss: 0.0664 - acc: 0.9722 - val_loss: 0.6346 - val_acc: 0.7465\n",
            "Epoch 302/500\n",
            "█████████ 0.0908s - loss: 0.0659 - acc: 0.9896 - val_loss: 0.5650 - val_acc: 0.7778\n",
            "Epoch 303/500\n",
            "█████████ 0.0818s - loss: 0.0977 - acc: 0.9896 - val_loss: 0.7771 - val_acc: 0.7639\n",
            "Epoch 304/500\n",
            "█████████ 0.0833s - loss: 0.0818 - acc: 0.9931 - val_loss: 0.3624 - val_acc: 0.7882\n",
            "Epoch 305/500\n",
            "█████████ 0.0829s - loss: 0.0470 - acc: 0.9931 - val_loss: 0.4917 - val_acc: 0.7500\n",
            "Epoch 306/500\n",
            "█████████ 0.0829s - loss: 0.0574 - acc: 0.9931 - val_loss: 0.3544 - val_acc: 0.7535\n",
            "Epoch 307/500\n",
            "█████████ 0.0858s - loss: 0.0565 - acc: 0.9896 - val_loss: 0.4861 - val_acc: 0.7743\n",
            "Epoch 308/500\n",
            "█████████ 0.0824s - loss: 0.0588 - acc: 0.9965 - val_loss: 0.6111 - val_acc: 0.7882\n",
            "Epoch 309/500\n",
            "█████████ 0.0803s - loss: 0.0789 - acc: 0.9792 - val_loss: 0.4973 - val_acc: 0.7847\n",
            "Epoch 310/500\n",
            "█████████ 0.0809s - loss: 0.0728 - acc: 0.9792 - val_loss: 0.6343 - val_acc: 0.7847\n",
            "Epoch 311/500\n",
            "█████████ 0.0892s - loss: 0.0560 - acc: 0.9931 - val_loss: 0.4244 - val_acc: 0.7882\n",
            "Epoch 312/500\n",
            "█████████ 0.0835s - loss: 0.0609 - acc: 0.9965 - val_loss: 0.5293 - val_acc: 0.7604\n",
            "Epoch 313/500\n",
            "█████████ 0.0841s - loss: 0.0493 - acc: 0.9965 - val_loss: 0.5122 - val_acc: 0.7500\n",
            "Epoch 314/500\n",
            "█████████ 0.0822s - loss: 0.0682 - acc: 0.9931 - val_loss: 0.4086 - val_acc: 0.7604\n",
            "Epoch 315/500\n",
            "█████████ 0.0890s - loss: 0.1255 - acc: 0.9896 - val_loss: 0.5137 - val_acc: 0.7500\n",
            "Epoch 316/500\n",
            "█████████ 0.0866s - loss: 0.0818 - acc: 0.9896 - val_loss: 0.3287 - val_acc: 0.7847\n",
            "Epoch 317/500\n",
            "█████████ 0.0983s - loss: 0.0896 - acc: 0.9931 - val_loss: 0.5019 - val_acc: 0.7847\n",
            "Epoch 318/500\n",
            "█████████ 0.0838s - loss: 0.0742 - acc: 0.9931 - val_loss: 0.5482 - val_acc: 0.7292\n",
            "Epoch 319/500\n",
            "█████████ 0.0816s - loss: 0.0604 - acc: 0.9931 - val_loss: 0.5304 - val_acc: 0.7535\n",
            "Epoch 320/500\n",
            "█████████ 0.0890s - loss: 0.0333 - acc: 1.0000 - val_loss: 0.6961 - val_acc: 0.7812\n",
            "Epoch 321/500\n",
            "█████████ 0.0767s - loss: 0.0586 - acc: 0.9931 - val_loss: 0.8373 - val_acc: 0.7778\n",
            "Epoch 322/500\n",
            "█████████ 0.0814s - loss: 0.0369 - acc: 0.9965 - val_loss: 0.5599 - val_acc: 0.7708\n",
            "Epoch 323/500\n",
            "█████████ 0.0800s - loss: 0.0631 - acc: 0.9965 - val_loss: 0.5568 - val_acc: 0.7674\n",
            "Epoch 324/500\n",
            "█████████ 0.0879s - loss: 0.0653 - acc: 0.9931 - val_loss: 0.4658 - val_acc: 0.7500\n",
            "Epoch 325/500\n",
            "█████████ 0.0867s - loss: 0.0532 - acc: 0.9896 - val_loss: 0.6904 - val_acc: 0.7500\n",
            "Epoch 326/500\n",
            "█████████ 0.0845s - loss: 0.0617 - acc: 0.9896 - val_loss: 0.7883 - val_acc: 0.7500\n",
            "Epoch 327/500\n",
            "█████████ 0.0757s - loss: 0.0312 - acc: 0.9965 - val_loss: 0.4634 - val_acc: 0.7535\n",
            "Epoch 328/500\n",
            "█████████ 0.0855s - loss: 0.0388 - acc: 0.9931 - val_loss: 0.8100 - val_acc: 0.7604\n",
            "Epoch 329/500\n",
            "█████████ 0.0894s - loss: 0.0387 - acc: 0.9931 - val_loss: 0.5393 - val_acc: 0.7604\n",
            "Epoch 330/500\n",
            "█████████ 0.0777s - loss: 0.0845 - acc: 0.9965 - val_loss: 0.4519 - val_acc: 0.7569\n",
            "Epoch 331/500\n",
            "█████████ 0.0893s - loss: 0.0675 - acc: 0.9931 - val_loss: 0.7928 - val_acc: 0.7396\n",
            "Epoch 332/500\n",
            "█████████ 0.0903s - loss: 0.0595 - acc: 0.9965 - val_loss: 0.7187 - val_acc: 0.7431\n",
            "Epoch 333/500\n",
            "█████████ 0.0819s - loss: 0.0235 - acc: 0.9965 - val_loss: 0.6784 - val_acc: 0.7465\n",
            "Epoch 334/500\n",
            "█████████ 0.0829s - loss: 0.0623 - acc: 0.9965 - val_loss: 0.8088 - val_acc: 0.7674\n",
            "Epoch 335/500\n",
            "█████████ 0.0788s - loss: 0.0444 - acc: 1.0000 - val_loss: 0.5782 - val_acc: 0.7639\n",
            "Epoch 336/500\n",
            "█████████ 0.0748s - loss: 0.0484 - acc: 0.9965 - val_loss: 0.6641 - val_acc: 0.7431\n",
            "Epoch 337/500\n",
            "█████████ 0.0789s - loss: 0.0588 - acc: 0.9965 - val_loss: 0.8655 - val_acc: 0.7639\n",
            "Epoch 338/500\n",
            "█████████ 0.0840s - loss: 0.0310 - acc: 0.9965 - val_loss: 0.4059 - val_acc: 0.7604\n",
            "Epoch 339/500\n",
            "█████████ 0.0775s - loss: 0.0398 - acc: 0.9965 - val_loss: 0.4187 - val_acc: 0.7778\n",
            "Epoch 340/500\n",
            "█████████ 0.0842s - loss: 0.0525 - acc: 0.9965 - val_loss: 0.3569 - val_acc: 0.7639\n",
            "Epoch 341/500\n",
            "█████████ 0.0810s - loss: 0.0884 - acc: 0.9931 - val_loss: 0.9488 - val_acc: 0.7604\n",
            "Epoch 342/500\n",
            "█████████ 0.0823s - loss: 0.0792 - acc: 0.9931 - val_loss: 0.6271 - val_acc: 0.7639\n",
            "Epoch 343/500\n",
            "█████████ 0.0799s - loss: 0.0467 - acc: 0.9965 - val_loss: 0.7692 - val_acc: 0.7569\n",
            "Epoch 344/500\n",
            "█████████ 0.0827s - loss: 0.0517 - acc: 0.9965 - val_loss: 0.4331 - val_acc: 0.7778\n",
            "Epoch 345/500\n",
            "█████████ 0.0793s - loss: 0.0879 - acc: 0.9965 - val_loss: 0.8881 - val_acc: 0.7674\n",
            "Epoch 346/500\n",
            "█████████ 0.0807s - loss: 0.0310 - acc: 0.9965 - val_loss: 0.7702 - val_acc: 0.7847\n",
            "Epoch 347/500\n",
            "█████████ 0.0772s - loss: 0.0386 - acc: 1.0000 - val_loss: 0.3184 - val_acc: 0.7708\n",
            "Epoch 348/500\n",
            "█████████ 0.0842s - loss: 0.0474 - acc: 0.9931 - val_loss: 0.8022 - val_acc: 0.7535\n",
            "Epoch 349/500\n",
            "█████████ 0.0787s - loss: 0.0412 - acc: 0.9931 - val_loss: 0.4016 - val_acc: 0.7535\n",
            "Epoch 350/500\n",
            "█████████ 0.0802s - loss: 0.0248 - acc: 0.9931 - val_loss: 0.6183 - val_acc: 0.7604\n",
            "Epoch 351/500\n",
            "█████████ 0.0753s - loss: 0.0705 - acc: 0.9965 - val_loss: 1.1401 - val_acc: 0.7674\n",
            "Epoch 352/500\n",
            "█████████ 0.0860s - loss: 0.0540 - acc: 0.9965 - val_loss: 0.6377 - val_acc: 0.7674\n",
            "Epoch 353/500\n",
            "█████████ 0.0873s - loss: 0.0325 - acc: 0.9965 - val_loss: 0.5802 - val_acc: 0.7639\n",
            "Epoch 354/500\n",
            "█████████ 0.0845s - loss: 0.0547 - acc: 0.9965 - val_loss: 0.8766 - val_acc: 0.7431\n",
            "Epoch 355/500\n",
            "█████████ 0.0805s - loss: 0.0416 - acc: 0.9965 - val_loss: 0.4537 - val_acc: 0.7743\n",
            "Epoch 356/500\n",
            "█████████ 0.0845s - loss: 0.0815 - acc: 0.9965 - val_loss: 0.6266 - val_acc: 0.7812\n",
            "Epoch 357/500\n",
            "█████████ 0.0867s - loss: 0.0343 - acc: 0.9965 - val_loss: 0.3811 - val_acc: 0.7639\n",
            "Epoch 358/500\n",
            "█████████ 0.0843s - loss: 0.0236 - acc: 0.9965 - val_loss: 0.6424 - val_acc: 0.7465\n",
            "Epoch 359/500\n",
            "█████████ 0.0794s - loss: 0.0397 - acc: 0.9861 - val_loss: 0.4601 - val_acc: 0.7569\n",
            "Epoch 360/500\n",
            "█████████ 0.0838s - loss: 0.0260 - acc: 0.9965 - val_loss: 0.5078 - val_acc: 0.7708\n",
            "Epoch 361/500\n",
            "█████████ 0.0859s - loss: 0.0684 - acc: 1.0000 - val_loss: 0.6130 - val_acc: 0.7743\n",
            "Epoch 362/500\n",
            "█████████ 0.0906s - loss: 0.0214 - acc: 0.9965 - val_loss: 0.5483 - val_acc: 0.7604\n",
            "Epoch 363/500\n",
            "█████████ 0.0828s - loss: 0.0394 - acc: 0.9965 - val_loss: 0.5020 - val_acc: 0.7639\n",
            "Epoch 364/500\n",
            "█████████ 0.0774s - loss: 0.0312 - acc: 0.9965 - val_loss: 0.4653 - val_acc: 0.7500\n",
            "Epoch 365/500\n",
            "█████████ 0.0796s - loss: 0.0303 - acc: 0.9826 - val_loss: 0.6219 - val_acc: 0.7361\n",
            "Epoch 366/500\n",
            "█████████ 0.0822s - loss: 0.0508 - acc: 0.9896 - val_loss: 0.8203 - val_acc: 0.7569\n",
            "Epoch 367/500\n",
            "█████████ 0.0851s - loss: 0.0268 - acc: 1.0000 - val_loss: 0.8170 - val_acc: 0.7465\n",
            "Epoch 368/500\n",
            "█████████ 0.0819s - loss: 0.0336 - acc: 0.9965 - val_loss: 0.3010 - val_acc: 0.7604\n",
            "Epoch 369/500\n",
            "█████████ 0.0857s - loss: 0.0629 - acc: 0.9965 - val_loss: 0.7376 - val_acc: 0.7431\n",
            "Epoch 370/500\n",
            "█████████ 0.0848s - loss: 0.0337 - acc: 0.9965 - val_loss: 0.3465 - val_acc: 0.7639\n",
            "Epoch 371/500\n",
            "█████████ 0.0829s - loss: 0.0680 - acc: 0.9931 - val_loss: 0.6384 - val_acc: 0.7569\n",
            "Epoch 372/500\n",
            "█████████ 0.0909s - loss: 0.0696 - acc: 0.9965 - val_loss: 0.3371 - val_acc: 0.7396\n",
            "Epoch 373/500\n",
            "█████████ 0.0772s - loss: 0.0287 - acc: 0.9965 - val_loss: 0.7092 - val_acc: 0.7500\n",
            "Epoch 374/500\n",
            "█████████ 0.0849s - loss: 0.0350 - acc: 0.9965 - val_loss: 0.6346 - val_acc: 0.7500\n",
            "Epoch 375/500\n",
            "█████████ 0.0833s - loss: 0.0276 - acc: 1.0000 - val_loss: 0.6909 - val_acc: 0.7535\n",
            "Epoch 376/500\n",
            "█████████ 0.0820s - loss: 0.0183 - acc: 0.9965 - val_loss: 0.5563 - val_acc: 0.7500\n",
            "Epoch 377/500\n",
            "█████████ 0.0822s - loss: 0.0728 - acc: 0.9931 - val_loss: 0.7037 - val_acc: 0.7604\n",
            "Epoch 378/500\n",
            "█████████ 0.0809s - loss: 0.0253 - acc: 0.9965 - val_loss: 0.5837 - val_acc: 0.7431\n",
            "Epoch 379/500\n",
            "█████████ 0.0781s - loss: 0.0188 - acc: 0.9965 - val_loss: 0.6812 - val_acc: 0.7500\n",
            "Epoch 380/500\n",
            "█████████ 0.0830s - loss: 0.0198 - acc: 1.0000 - val_loss: 0.9698 - val_acc: 0.7674\n",
            "Epoch 381/500\n",
            "█████████ 0.0778s - loss: 0.0306 - acc: 0.9965 - val_loss: 0.4003 - val_acc: 0.7465\n",
            "Epoch 382/500\n",
            "█████████ 0.0873s - loss: 0.0290 - acc: 1.0000 - val_loss: 0.8986 - val_acc: 0.7569\n",
            "Epoch 383/500\n",
            "█████████ 0.0830s - loss: 0.0288 - acc: 1.0000 - val_loss: 0.3049 - val_acc: 0.7569\n",
            "Epoch 384/500\n",
            "█████████ 0.0815s - loss: 0.0326 - acc: 0.9965 - val_loss: 0.4293 - val_acc: 0.7431\n",
            "Epoch 385/500\n",
            "█████████ 0.0850s - loss: 0.0284 - acc: 0.9965 - val_loss: 0.6417 - val_acc: 0.7674\n",
            "Epoch 386/500\n",
            "█████████ 0.0907s - loss: 0.0266 - acc: 0.9965 - val_loss: 0.5410 - val_acc: 0.7465\n",
            "Epoch 387/500\n",
            "█████████ 0.0786s - loss: 0.0302 - acc: 0.9965 - val_loss: 0.6162 - val_acc: 0.7292\n",
            "Epoch 388/500\n",
            "█████████ 0.0805s - loss: 0.0184 - acc: 1.0000 - val_loss: 1.0663 - val_acc: 0.7500\n",
            "Epoch 389/500\n",
            "█████████ 0.0815s - loss: 0.0330 - acc: 0.9965 - val_loss: 0.5644 - val_acc: 0.7500\n",
            "Epoch 390/500\n",
            "█████████ 0.0800s - loss: 0.0541 - acc: 0.9931 - val_loss: 0.3501 - val_acc: 0.7361\n",
            "Epoch 391/500\n",
            "█████████ 0.0778s - loss: 0.0259 - acc: 0.9965 - val_loss: 0.4763 - val_acc: 0.7361\n",
            "Epoch 392/500\n",
            "█████████ 0.0869s - loss: 0.0392 - acc: 0.9931 - val_loss: 0.8236 - val_acc: 0.7569\n",
            "Epoch 393/500\n",
            "█████████ 0.0843s - loss: 0.0119 - acc: 0.9965 - val_loss: 0.9682 - val_acc: 0.7708\n",
            "Epoch 394/500\n",
            "█████████ 0.0879s - loss: 0.0177 - acc: 0.9931 - val_loss: 0.8915 - val_acc: 0.7535\n",
            "Epoch 395/500\n",
            "█████████ 0.0883s - loss: 0.0307 - acc: 0.9965 - val_loss: 0.7218 - val_acc: 0.7569\n",
            "Epoch 396/500\n",
            "█████████ 0.0821s - loss: 0.0219 - acc: 0.9965 - val_loss: 1.2487 - val_acc: 0.7396\n",
            "Epoch 397/500\n",
            "█████████ 0.0790s - loss: 0.0301 - acc: 0.9931 - val_loss: 0.6740 - val_acc: 0.7257\n",
            "Epoch 398/500\n",
            "█████████ 0.0795s - loss: 0.0410 - acc: 0.9896 - val_loss: 0.8298 - val_acc: 0.7361\n",
            "Epoch 399/500\n",
            "█████████ 0.0783s - loss: 0.0275 - acc: 1.0000 - val_loss: 0.5136 - val_acc: 0.7708\n",
            "Epoch 400/500\n",
            "█████████ 0.0775s - loss: 0.0312 - acc: 0.9965 - val_loss: 0.9084 - val_acc: 0.7674\n",
            "Epoch 401/500\n",
            "█████████ 0.0780s - loss: 0.0369 - acc: 1.0000 - val_loss: 0.7314 - val_acc: 0.7708\n",
            "Epoch 402/500\n",
            "█████████ 0.0789s - loss: 0.0292 - acc: 1.0000 - val_loss: 0.7921 - val_acc: 0.7778\n",
            "Epoch 403/500\n",
            "█████████ 0.0818s - loss: 0.0232 - acc: 0.9965 - val_loss: 0.7142 - val_acc: 0.7639\n",
            "Epoch 404/500\n",
            "█████████ 0.0894s - loss: 0.0320 - acc: 0.9965 - val_loss: 0.8348 - val_acc: 0.7674\n",
            "Epoch 405/500\n",
            "█████████ 0.0898s - loss: 0.0202 - acc: 0.9965 - val_loss: 0.5100 - val_acc: 0.7743\n",
            "Epoch 406/500\n",
            "█████████ 0.0843s - loss: 0.0300 - acc: 1.0000 - val_loss: 0.5325 - val_acc: 0.7708\n",
            "Epoch 407/500\n",
            "█████████ 0.0774s - loss: 0.0109 - acc: 1.0000 - val_loss: 0.6721 - val_acc: 0.7604\n",
            "Epoch 408/500\n",
            "█████████ 0.0861s - loss: 0.0170 - acc: 1.0000 - val_loss: 0.4790 - val_acc: 0.7604\n",
            "Epoch 409/500\n",
            "█████████ 0.0808s - loss: 0.0681 - acc: 0.9965 - val_loss: 0.8081 - val_acc: 0.7535\n",
            "Epoch 410/500\n",
            "█████████ 0.0866s - loss: 0.0227 - acc: 1.0000 - val_loss: 0.7690 - val_acc: 0.7847\n",
            "Epoch 411/500\n",
            "█████████ 0.0808s - loss: 0.0295 - acc: 0.9931 - val_loss: 0.4659 - val_acc: 0.7465\n",
            "Epoch 412/500\n",
            "█████████ 0.0776s - loss: 0.0909 - acc: 0.9896 - val_loss: 0.8875 - val_acc: 0.7396\n",
            "Epoch 413/500\n",
            "█████████ 0.0817s - loss: 0.0194 - acc: 1.0000 - val_loss: 0.7987 - val_acc: 0.7674\n",
            "Epoch 414/500\n",
            "█████████ 0.0854s - loss: 0.0357 - acc: 1.0000 - val_loss: 0.6565 - val_acc: 0.7674\n",
            "Epoch 415/500\n",
            "█████████ 0.0805s - loss: 0.0198 - acc: 0.9965 - val_loss: 0.6183 - val_acc: 0.7569\n",
            "Epoch 416/500\n",
            "█████████ 0.0815s - loss: 0.0300 - acc: 0.9965 - val_loss: 0.5489 - val_acc: 0.7569\n",
            "Epoch 417/500\n",
            "█████████ 0.0792s - loss: 0.0203 - acc: 1.0000 - val_loss: 0.7123 - val_acc: 0.7535\n",
            "Epoch 418/500\n",
            "█████████ 0.0792s - loss: 0.0114 - acc: 0.9965 - val_loss: 0.8429 - val_acc: 0.7674\n",
            "Epoch 419/500\n",
            "█████████ 0.0869s - loss: 0.0658 - acc: 0.9931 - val_loss: 0.6716 - val_acc: 0.7500\n",
            "Epoch 420/500\n",
            "█████████ 0.0871s - loss: 0.0201 - acc: 0.9965 - val_loss: 0.8659 - val_acc: 0.7604\n",
            "Epoch 421/500\n",
            "█████████ 0.0812s - loss: 0.0569 - acc: 1.0000 - val_loss: 0.8966 - val_acc: 0.7604\n",
            "Epoch 422/500\n",
            "█████████ 0.0824s - loss: 0.0416 - acc: 0.9965 - val_loss: 0.8748 - val_acc: 0.7500\n",
            "Epoch 423/500\n",
            "█████████ 0.0796s - loss: 0.0101 - acc: 1.0000 - val_loss: 0.6143 - val_acc: 0.7604\n",
            "Epoch 424/500\n",
            "█████████ 0.0917s - loss: 0.0091 - acc: 1.0000 - val_loss: 0.8032 - val_acc: 0.7674\n",
            "Epoch 425/500\n",
            "█████████ 0.0773s - loss: 0.0298 - acc: 1.0000 - val_loss: 0.4980 - val_acc: 0.7465\n",
            "Epoch 426/500\n",
            "█████████ 0.0890s - loss: 0.0121 - acc: 1.0000 - val_loss: 0.3441 - val_acc: 0.7604\n",
            "Epoch 427/500\n",
            "█████████ 0.0799s - loss: 0.0150 - acc: 0.9965 - val_loss: 0.3633 - val_acc: 0.7431\n",
            "Epoch 428/500\n",
            "█████████ 0.0832s - loss: 0.0412 - acc: 1.0000 - val_loss: 1.0078 - val_acc: 0.7604\n",
            "Epoch 429/500\n",
            "█████████ 0.0815s - loss: 0.0184 - acc: 1.0000 - val_loss: 0.7474 - val_acc: 0.7604\n",
            "Epoch 430/500\n",
            "█████████ 0.0782s - loss: 0.0376 - acc: 1.0000 - val_loss: 0.3380 - val_acc: 0.7639\n",
            "Epoch 431/500\n",
            "█████████ 0.0777s - loss: 0.0180 - acc: 1.0000 - val_loss: 0.1860 - val_acc: 0.7743\n",
            "Epoch 432/500\n",
            "█████████ 0.0846s - loss: 0.0188 - acc: 1.0000 - val_loss: 0.7618 - val_acc: 0.7639\n",
            "Epoch 433/500\n",
            "█████████ 0.0760s - loss: 0.0312 - acc: 1.0000 - val_loss: 0.5973 - val_acc: 0.7431\n",
            "Epoch 434/500\n",
            "█████████ 0.0932s - loss: 0.0288 - acc: 0.9931 - val_loss: 0.8744 - val_acc: 0.7535\n",
            "Epoch 435/500\n",
            "█████████ 0.0792s - loss: 0.0551 - acc: 0.9965 - val_loss: 0.6300 - val_acc: 0.7396\n",
            "Epoch 436/500\n",
            "█████████ 0.0812s - loss: 0.0139 - acc: 0.9965 - val_loss: 0.6498 - val_acc: 0.7639\n",
            "Epoch 437/500\n",
            "█████████ 0.0798s - loss: 0.0222 - acc: 1.0000 - val_loss: 0.5484 - val_acc: 0.7674\n",
            "Epoch 438/500\n",
            "█████████ 0.0854s - loss: 0.0242 - acc: 1.0000 - val_loss: 0.9904 - val_acc: 0.7743\n",
            "Epoch 439/500\n",
            "█████████ 0.0766s - loss: 0.0290 - acc: 1.0000 - val_loss: 0.7769 - val_acc: 0.7674\n",
            "Epoch 440/500\n",
            "█████████ 0.0846s - loss: 0.0360 - acc: 1.0000 - val_loss: 0.8948 - val_acc: 0.7569\n",
            "Epoch 441/500\n",
            "█████████ 0.0774s - loss: 0.0439 - acc: 1.0000 - val_loss: 0.3067 - val_acc: 0.7326\n",
            "Epoch 442/500\n",
            "█████████ 0.0840s - loss: 0.0220 - acc: 1.0000 - val_loss: 0.3559 - val_acc: 0.7396\n",
            "Epoch 443/500\n",
            "█████████ 0.0844s - loss: 0.0201 - acc: 0.9965 - val_loss: 0.9540 - val_acc: 0.7569\n",
            "Epoch 444/500\n",
            "█████████ 0.0834s - loss: 0.0191 - acc: 1.0000 - val_loss: 0.8645 - val_acc: 0.7639\n",
            "Epoch 445/500\n",
            "█████████ 0.0881s - loss: 0.0122 - acc: 1.0000 - val_loss: 0.4551 - val_acc: 0.7604\n",
            "Epoch 446/500\n",
            "█████████ 0.0791s - loss: 0.0200 - acc: 1.0000 - val_loss: 0.4080 - val_acc: 0.7639\n",
            "Epoch 447/500\n",
            "█████████ 0.0784s - loss: 0.0121 - acc: 1.0000 - val_loss: 0.6449 - val_acc: 0.7812\n",
            "Epoch 448/500\n",
            "█████████ 0.0853s - loss: 0.0135 - acc: 1.0000 - val_loss: 0.5876 - val_acc: 0.7674\n",
            "Epoch 449/500\n",
            "█████████ 0.0811s - loss: 0.0152 - acc: 1.0000 - val_loss: 0.9144 - val_acc: 0.7431\n",
            "Epoch 450/500\n",
            "█████████ 0.0780s - loss: 0.0122 - acc: 1.0000 - val_loss: 0.8652 - val_acc: 0.7604\n",
            "Epoch 451/500\n",
            "█████████ 0.0812s - loss: 0.0178 - acc: 1.0000 - val_loss: 0.8795 - val_acc: 0.7639\n",
            "Epoch 452/500\n",
            "█████████ 0.0832s - loss: 0.0150 - acc: 1.0000 - val_loss: 0.8194 - val_acc: 0.7639\n",
            "Epoch 453/500\n",
            "█████████ 0.0778s - loss: 0.0277 - acc: 0.9965 - val_loss: 0.5836 - val_acc: 0.7569\n",
            "Epoch 454/500\n",
            "█████████ 0.0774s - loss: 0.0361 - acc: 1.0000 - val_loss: 0.3579 - val_acc: 0.7674\n",
            "Epoch 455/500\n",
            "█████████ 0.0794s - loss: 0.0094 - acc: 1.0000 - val_loss: 0.8314 - val_acc: 0.7778\n",
            "Epoch 456/500\n",
            "█████████ 0.0814s - loss: 0.0210 - acc: 1.0000 - val_loss: 0.3592 - val_acc: 0.7674\n",
            "Epoch 457/500\n",
            "█████████ 0.0829s - loss: 0.0163 - acc: 1.0000 - val_loss: 0.5407 - val_acc: 0.7500\n",
            "Epoch 458/500\n",
            "█████████ 0.0817s - loss: 0.0275 - acc: 1.0000 - val_loss: 0.5968 - val_acc: 0.7674\n",
            "Epoch 459/500\n",
            "█████████ 0.0812s - loss: 0.0088 - acc: 1.0000 - val_loss: 0.8676 - val_acc: 0.7535\n",
            "Epoch 460/500\n",
            "█████████ 0.0862s - loss: 0.0385 - acc: 0.9965 - val_loss: 1.1995 - val_acc: 0.7674\n",
            "Epoch 461/500\n",
            "█████████ 0.0795s - loss: 0.0124 - acc: 1.0000 - val_loss: 0.9478 - val_acc: 0.7639\n",
            "Epoch 462/500\n",
            "█████████ 0.0902s - loss: 0.0107 - acc: 1.0000 - val_loss: 0.5263 - val_acc: 0.7778\n",
            "Epoch 463/500\n",
            "█████████ 0.0833s - loss: 0.0096 - acc: 1.0000 - val_loss: 0.6805 - val_acc: 0.7569\n",
            "Epoch 464/500\n",
            "█████████ 0.0829s - loss: 0.0162 - acc: 1.0000 - val_loss: 0.5142 - val_acc: 0.7812\n",
            "Epoch 465/500\n",
            "█████████ 0.0839s - loss: 0.0138 - acc: 1.0000 - val_loss: 0.6532 - val_acc: 0.7743\n",
            "Epoch 466/500\n",
            "█████████ 0.0798s - loss: 0.0271 - acc: 1.0000 - val_loss: 0.9851 - val_acc: 0.7778\n",
            "Epoch 467/500\n",
            "█████████ 0.0810s - loss: 0.0181 - acc: 1.0000 - val_loss: 0.4638 - val_acc: 0.7604\n",
            "Epoch 468/500\n",
            "█████████ 0.0796s - loss: 0.0240 - acc: 1.0000 - val_loss: 0.7116 - val_acc: 0.7674\n",
            "Epoch 469/500\n",
            "█████████ 0.0782s - loss: 0.0246 - acc: 1.0000 - val_loss: 0.6832 - val_acc: 0.7639\n",
            "Epoch 470/500\n",
            "█████████ 0.0804s - loss: 0.0109 - acc: 1.0000 - val_loss: 0.4186 - val_acc: 0.7500\n",
            "Epoch 471/500\n",
            "█████████ 0.0797s - loss: 0.0174 - acc: 1.0000 - val_loss: 0.6782 - val_acc: 0.7639\n",
            "Epoch 472/500\n",
            "█████████ 0.0824s - loss: 0.0140 - acc: 1.0000 - val_loss: 0.6460 - val_acc: 0.7500\n",
            "Epoch 473/500\n",
            "█████████ 0.0789s - loss: 0.0128 - acc: 1.0000 - val_loss: 0.7545 - val_acc: 0.7569\n",
            "Epoch 474/500\n",
            "█████████ 0.0810s - loss: 0.0134 - acc: 1.0000 - val_loss: 0.7039 - val_acc: 0.7569\n",
            "Epoch 475/500\n",
            "█████████ 0.0764s - loss: 0.0177 - acc: 0.9965 - val_loss: 0.7241 - val_acc: 0.7535\n",
            "Epoch 476/500\n",
            "█████████ 0.0781s - loss: 0.0150 - acc: 1.0000 - val_loss: 0.4479 - val_acc: 0.7535\n",
            "Epoch 477/500\n",
            "█████████ 0.0788s - loss: 0.0269 - acc: 0.9931 - val_loss: 0.4293 - val_acc: 0.7396\n",
            "Epoch 478/500\n",
            "█████████ 0.0795s - loss: 0.0111 - acc: 1.0000 - val_loss: 0.7812 - val_acc: 0.7812\n",
            "Epoch 479/500\n",
            "█████████ 0.0773s - loss: 0.0244 - acc: 1.0000 - val_loss: 0.4923 - val_acc: 0.7569\n",
            "Epoch 480/500\n",
            "█████████ 0.0846s - loss: 0.0090 - acc: 0.9965 - val_loss: 0.8582 - val_acc: 0.7639\n",
            "Epoch 481/500\n",
            "█████████ 0.0849s - loss: 0.0201 - acc: 1.0000 - val_loss: 0.5903 - val_acc: 0.7604\n",
            "Epoch 482/500\n",
            "█████████ 0.0758s - loss: 0.0071 - acc: 1.0000 - val_loss: 0.7411 - val_acc: 0.7708\n",
            "Epoch 483/500\n",
            "█████████ 0.0811s - loss: 0.0239 - acc: 1.0000 - val_loss: 0.4790 - val_acc: 0.7812\n",
            "Epoch 484/500\n",
            "█████████ 0.0826s - loss: 0.0208 - acc: 1.0000 - val_loss: 0.9360 - val_acc: 0.7778\n",
            "Epoch 485/500\n",
            "█████████ 0.0849s - loss: 0.0060 - acc: 1.0000 - val_loss: 0.6305 - val_acc: 0.7743\n",
            "Epoch 486/500\n",
            "█████████ 0.0839s - loss: 0.0240 - acc: 1.0000 - val_loss: 1.1569 - val_acc: 0.7431\n",
            "Epoch 487/500\n",
            "█████████ 0.0804s - loss: 0.0139 - acc: 1.0000 - val_loss: 0.5113 - val_acc: 0.7396\n",
            "Epoch 488/500\n",
            "█████████ 0.0784s - loss: 0.0103 - acc: 1.0000 - val_loss: 0.9119 - val_acc: 0.7569\n",
            "Epoch 489/500\n",
            "█████████ 0.0777s - loss: 0.0280 - acc: 0.9965 - val_loss: 0.7358 - val_acc: 0.7639\n",
            "Epoch 490/500\n",
            "█████████ 0.0825s - loss: 0.0166 - acc: 1.0000 - val_loss: 0.6090 - val_acc: 0.7674\n",
            "Epoch 491/500\n",
            "█████████ 0.0788s - loss: 0.0081 - acc: 1.0000 - val_loss: 0.7684 - val_acc: 0.7535\n",
            "Epoch 492/500\n",
            "█████████ 0.0763s - loss: 0.0200 - acc: 1.0000 - val_loss: 0.9338 - val_acc: 0.7535\n",
            "Epoch 493/500\n",
            "█████████ 0.0802s - loss: 0.0175 - acc: 0.9965 - val_loss: 0.5556 - val_acc: 0.7639\n",
            "Epoch 494/500\n",
            "█████████ 0.0836s - loss: 0.0214 - acc: 1.0000 - val_loss: 0.6191 - val_acc: 0.7569\n",
            "Epoch 495/500\n",
            "█████████ 0.0788s - loss: 0.0448 - acc: 1.0000 - val_loss: 0.5555 - val_acc: 0.7500\n",
            "Epoch 496/500\n",
            "█████████ 0.0800s - loss: 0.0120 - acc: 1.0000 - val_loss: 0.8484 - val_acc: 0.7708\n",
            "Epoch 497/500\n",
            "█████████ 0.0946s - loss: 0.0120 - acc: 1.0000 - val_loss: 0.7279 - val_acc: 0.7639\n",
            "Epoch 498/500\n",
            "█████████ 0.0854s - loss: 0.0159 - acc: 0.9965 - val_loss: 0.1356 - val_acc: 0.7535\n",
            "Epoch 499/500\n",
            "█████████ 0.0805s - loss: 0.0318 - acc: 1.0000 - val_loss: 1.0320 - val_acc: 0.7396\n",
            "Epoch 500/500\n",
            "█████████ 0.0783s - loss: 0.0237 - acc: 1.0000 - val_loss: 0.8854 - val_acc: 0.7535\n",
            "Accuracy: 1.0000\tLoss: 0.0137\n",
            "Accuracy: 0.7535\tLoss: 0.7029\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7028931975364685, 0.7534722222222222)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "xXYWpvykISLI",
        "outputId": "f637cc97-9b8f-48cf-cf5b-5d8c17f2a3fb"
      },
      "source": [
        "plt.figure(figsize = (10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Acc\")\n",
        "plt.plot(history[\"acc\"], color=\"red\")\n",
        "plt.plot(history[\"val_acc\"], color=\"blue\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Loss\")\n",
        "plt.plot(history[\"loss\"], color=\"red\")\n",
        "plt.plot(history[\"val_loss\"], color=\"blue\")\n",
        "plt.show()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTCYiI_QI084"
      },
      "source": [
        "ref"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNHGkN8UZgA2"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SCCNet().to(device)\n",
        "summary(model, (1, 22, 562))\n",
        "cmp = Tensor().numpy() == np.array()\n",
        "cmp.all()"
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}